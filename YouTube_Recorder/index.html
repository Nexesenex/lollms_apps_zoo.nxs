<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YouTube Recorder</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/wavesurfer.js"></script>
    <script src="/lollms_assets/js/lollms_client_js"></script>
    <script src="/lollms_assets/js/axios.min"></script>
</head>
<body class="bg-gradient-to-r from-blue-100 to-purple-100 font-sans">
    <div class="container mx-auto px-4 py-8">
        <header class="text-center mb-8">
            <h1 class="text-4xl font-bold text-indigo-800 mb-2">YouTube Recorder</h1>
            <p class="text-gray-600">Record your screen and audio for YouTube videos</p>
        </header>

        <div class="bg-white shadow-lg rounded-lg p-6 mb-8">
            <div class="flex justify-center space-x-4 mb-4">
                <button id="startBtn" class="bg-indigo-600 hover:bg-indigo-700 text-white font-bold py-2 px-4 rounded transition duration-300">
                    Start Recording
                </button>
                <button id="stopBtn" class="bg-red-600 hover:bg-red-700 text-white font-bold py-2 px-4 rounded transition duration-300 hidden">
                    Stop Recording
                </button>
            </div>
            <p id="status" class="text-center text-gray-600">Ready to record</p>
        </div>

        <div class="bg-white shadow-lg rounded-lg p-6 mb-8">
            <h2 class="text-2xl font-bold mb-4 text-indigo-800">Video Preview</h2>
            <video id="videoPreview" class="w-full h-auto mb-4" controls></video>
            <div class="flex justify-center space-x-4 mb-4">
                <button id="loadVideo" class="bg-indigo-600 hover:bg-indigo-700 text-white font-bold py-2 px-4 rounded transition duration-300">
                    Load Video
                </button>
                <button id="downloadVideo" class="bg-green-600 hover:bg-green-700 text-white font-bold py-2 px-4 rounded transition duration-300" disabled>
                    Download Video
                </button>
                <button id="extractAudio" class="bg-yellow-600 hover:bg-yellow-700 text-white font-bold py-2 px-4 rounded transition duration-300">
                    Extract Audio
                </button>
            </div>
            <h2 class="text-2xl font-bold mb-4 text-indigo-800">Audio Preview</h2>
            <div id="waveform"></div>
            <audio id="audioPreview" class="w-full mt-4" controls></audio>
            <div class="flex justify-center space-x-4 mt-4">
                <button id="loadAudio" class="bg-indigo-600 hover:bg-indigo-700 text-white font-bold py-2 px-4 rounded transition duration-300">
                    Load Audio
                </button>
                <button id="downloadAudio" class="bg-green-600 hover:bg-green-700 text-white font-bold py-2 px-4 rounded transition duration-300" disabled>
                    Download Audio
                </button>
            </div>
            <div class="mt-4">
                <h3 class="text-xl font-bold mb-2 text-indigo-800">Transcription</h3>
                <textarea id="transcriptionText" class="w-full h-40 p-2 border border-indigo-300 rounded-md focus:outline-none focus:ring-2 focus:ring-indigo-500"></textarea>
            </div>
            <div class="mt-4">
                <h3 class="text-xl font-bold mb-2 text-indigo-800">Enhanced Text</h3>
                <textarea id="enhancedText" class="w-full h-40 p-2 border border-indigo-300 rounded-md focus:outline-none focus:ring-2 focus:ring-indigo-500"></textarea>
            </div>
            <div id="voiceSelectionContainer" class="mt-4">
                <h3 class="text-xl font-bold mb-2 text-indigo-800">Select Voice</h3>
                <select id="voiceSelect" class="w-full p-2 border border-indigo-300 rounded-md focus:outline-none focus:ring-2 focus:ring-indigo-500"></select>
            </div>
            <div id="languageSelectionContainer" class="mt-4">
                <h3 class="text-xl font-bold mb-2 text-indigo-800">Select Language</h3>
                <select id="languageSelect" class="w-full p-2 border border-indigo-300 rounded-md focus:outline-none focus:ring-2 focus:ring-indigo-500">
                    <option value="en">English</option>
                    <option value="fr">French</option>
                    <option value="es">Spanish</option>
                    <option value="de">German</option>
                    <option value="it">Italian</option>
                </select>
            </div>
            <h2 class="text-2xl font-bold mb-4 text-indigo-800">Enhanced Audio Preview</h2>
            <div id="enhancedwaveform"></div>
            <audio id="enhancedAudioPreview" class="w-full mt-4" controls></audio>
        </div>

        <div class="bg-white shadow-lg rounded-lg p-6 mb-8">
            <h2 class="text-2xl font-bold mb-4 text-indigo-800">Actions</h2>
            <div class="flex flex-wrap justify-center space-x-4">
                <button id="transcribeBtn" class="bg-indigo-600 hover:bg-indigo-700 text-white font-bold py-2 px-4 rounded transition duration-300 mb-2" disabled>
                    Transcribe
                </button>
                <button id="enhanceBtn" class="bg-green-600 hover:bg-green-700 text-white font-bold py-2 px-4 rounded transition duration-300 mb-2" disabled>
                    Enhance
                </button>
                <button id="synthesizeBtn" class="bg-indigo-600 hover:bg-indigo-700 text-white font-bold py-2 px-4 rounded transition duration-300 mb-2" disabled>
                    Synthesize
                </button>
            </div>
        </div>

        <div class="bg-white shadow-lg rounded-lg p-6 mb-8">
            <h2 class="text-2xl font-bold mb-4 text-indigo-800">Project Management</h2>
            <div class="flex flex-wrap justify-center space-x-4">
                <button id="saveProject" class="bg-green-600 hover:bg-green-700 text-white font-bold py-2 px-4 rounded transition duration-300 mb-2">
                    Save Project
                </button>
                <button id="loadProject" class="bg-indigo-600 hover:bg-indigo-700 text-white font-bold py-2 px-4 rounded transition duration-300 mb-2">
                    Load Project
                </button>
            </div>
        </div>

        <footer class="text-center text-gray-600">
            <p>&copy; 2023 YouTube Recorder. All rights reserved.</p>
        </footer>
    </div>

    <div id="loadingOverlay" class="fixed inset-0 bg-white bg-opacity-80 z-50 flex justify-center items-center" style="display: none;">
        <div class="text-center">
            <div class="text-6xl animate-spin">üçì</div>
            <div class="mt-4">Processing...</div>
        </div>
    </div>

    <script>
        let mediaRecorder;
        let recordedChunks = [];
        let audioContext;
        let audioStream;
        let videoStream;
        let wavesurfer;
        const lc = new LollmsClient();

        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const status = document.getElementById('status');
        const videoPreview = document.getElementById('videoPreview');
        const audioPreview = document.getElementById('audioPreview');
        const loadVideo = document.getElementById('loadVideo');
        const loadAudio = document.getElementById('loadAudio');
        const downloadVideo = document.getElementById('downloadVideo');
        const downloadAudio = document.getElementById('downloadAudio');
        const transcribeBtn = document.getElementById('transcribeBtn');
        const enhanceBtn = document.getElementById('enhanceBtn');
        const synthesizeBtn = document.getElementById('synthesizeBtn');
        const transcriptionText = document.getElementById('transcriptionText');
        const enhancedText = document.getElementById('enhancedText');
        const voiceSelectionContainer = document.getElementById('voiceSelectionContainer');
        const voiceSelect = document.getElementById('voiceSelect');
        const languageSelect = document.getElementById('languageSelect');
        const loadingOverlay = document.getElementById('loadingOverlay');
        const saveProjectBtn = document.getElementById('saveProject');
        const loadProjectBtn = document.getElementById('loadProject');
        const extractAudioBtn = document.getElementById('extractAudio');

        wavesurfer = WaveSurfer.create({
            container: '#waveform',
            waveColor: 'violet',
            progressColor: 'purple'
        });

        startBtn.addEventListener('click', startRecording);
        stopBtn.addEventListener('click', stopRecording);
        loadVideo.addEventListener('click', () => loadMedia('video'));
        loadAudio.addEventListener('click', () => loadMedia('audio'));
        downloadVideo.addEventListener('click', () => downloadMedia('video'));
        downloadAudio.addEventListener('click', () => downloadMedia('audio'));
        transcribeBtn.addEventListener('click', transcribeAudio);
        enhanceBtn.addEventListener('click', enhanceTranscription);
        synthesizeBtn.addEventListener('click', synthesizeSpeech);
        saveProjectBtn.addEventListener('click', saveProject);
        loadProjectBtn.addEventListener('click', loadProject);
        extractAudioBtn.addEventListener('click', extractAudio);

        async function startRecording() {
            try {
                videoStream = await navigator.mediaDevices.getDisplayMedia({ video: true });
                audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });

                const combinedStream = new MediaStream([
                    ...videoStream.getTracks(),
                    ...audioStream.getTracks()
                ]);

                mediaRecorder = new MediaRecorder(combinedStream);

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        recordedChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = processRecording;

                mediaRecorder.start();
                startBtn.classList.add("hidden");
                stopBtn.classList.remove("hidden");
                status.textContent = 'Recording in progress';

                audioContext = new AudioContext();
                const source = audioContext.createMediaStreamSource(audioStream);
                const analyser = audioContext.createAnalyser();
                source.connect(analyser);

                const dataArray = new Uint8Array(analyser.frequencyBinCount);
                function updateWaveform() {
                    analyser.getByteTimeDomainData(dataArray);
                    const normalizedData = Array.from(dataArray).map(val => (val / 128) - 1);
                    wavesurfer.load('', normalizedData);
                    requestAnimationFrame(updateWaveform);
                }
                updateWaveform();

            } catch (error) {
                console.error('Error starting recording:', error);
                status.textContent = 'Error: ' + error.message;
            }
        }

        function stopRecording() {
            mediaRecorder.stop();
            videoStream.getTracks().forEach(track => track.stop());
            audioStream.getTracks().forEach(track => track.stop());
            startBtn.classList.remove("hidden");
            stopBtn.classList.add("hidden");

            status.textContent = 'Recording stopped';
            showLoading();
        }

        function processRecording() {
            const videoBlob = new Blob(recordedChunks, { type: 'video/webm' });
            const videoUrl = URL.createObjectURL(videoBlob);
            videoPreview.src = videoUrl;

            const audioBlob = new Blob(recordedChunks, { type: 'audio/webm' });
            const audioUrl = URL.createObjectURL(audioBlob);
            wavesurfer.load(audioUrl);
            audioPreview.src = audioUrl;

            downloadVideo.disabled = false;
            downloadAudio.disabled = false;
            transcribeBtn.disabled = false;
            hideLoading();
        }

        function loadMedia(type) {
            const input = document.createElement('input');
            input.type = 'file';
            input.accept = type === 'video' ? 'video/*' : 'audio/*';
            input.onchange = (e) => {
                const file = e.target.files[0];
                const url = URL.createObjectURL(file);
                if (type === 'video') {
                    videoPreview.src = url;
                    downloadVideo.disabled = false;
                } else {
                    audioPreview.src = url;
                    wavesurfer.load(url);
                    downloadAudio.disabled = false;
                }
                transcribeBtn.disabled = false;
            };
            input.click();
        }

        function downloadMedia(type) {
            const element = type === 'video' ? videoPreview : audioPreview;
            const url = element.src;
            const a = document.createElement('a');
            a.style.display = 'none';
            a.href = url;
            a.download = `recorded_${type}.${type === 'video' ? 'webm' : 'wav'}`;
            document.body.appendChild(a);
            a.click();
            setTimeout(() => {
                document.body.removeChild(a);
                window.URL.revokeObjectURL(url);
            }, 100);
        }

        async function transcribeAudio() {
            showLoading();
            try {
                const audioBlob = await fetch(audioPreview.src).then(r => r.blob());
                const formData = new FormData();
                formData.append('file', audioBlob, 'audio.wav');

                const response = await axios.post('/transcribe', formData, {
                    headers: { 'Content-Type': 'multipart/form-data' }
                });

                transcriptionText.value = response.data.transcription;
                enhanceBtn.disabled = false;
            } catch (error) {
                console.error('Transcription error:', error);
                alert('Error during transcription');
            } finally {
                hideLoading();
            }
        }

        async function enhanceTranscription() {
            showLoading();
            try {
                const prompt = `${lc.system_message()}Enhance the following transcription, improving clarity and coherence:\n\n${transcriptionText.value}\nPlease answer directly with the enhanced transcription without any comments.\n${lc.ai_message()}`;
                const enhancedResponse = await lc.generate(prompt);
                enhancedText.value = enhancedResponse;
                synthesizeBtn.disabled = false;
                loadVoices();
            } catch (error) {
console.error('Enhancement error:', error);
                alert('Error during enhancement');
            } finally {
                hideLoading();
            }
        }

        async function loadVoices() {
            try {
                const response = await axios.get('/tts/voices');
                const voices = response.data.voices;
                voiceSelect.innerHTML = voices.map(voice => `<option value="${voice}">${voice}</option>`).join('');
                voiceSelectionContainer.style.display = 'block';
            } catch (error) {
                console.error('Error loading voices:', error);
                alert('Error loading voices');
            }
        }

        async function synthesizeSpeech() {
            showLoading();
            try {
                const selectedVoice = voiceSelect.value;
                const selectedLanguage = languageSelect.value;
                const textToSynthesize = enhancedText.value;

                const response = await axios.post('/tts/file', {
                    text: textToSynthesize,
                    speaker: selectedVoice,
                    language: selectedLanguage
                }, {
                    responseType: 'blob'
                });

                const audioBlob = new Blob([response.data], { type: 'audio/wav' });
                const audioUrl = URL.createObjectURL(audioBlob);
                const enhancedAudioPreview = document.getElementById('enhancedAudioPreview');
                enhancedAudioPreview.src = audioUrl;
                WaveSurfer.create({
                    container: '#enhancedwaveform',
                    waveColor: 'violet',
                    progressColor: 'purple'
                }).load(audioUrl);
            } catch (error) {
                console.error('Speech synthesis error:', error);
                alert('Error during speech synthesis');
            } finally {
                hideLoading();
            }
        }

        function showLoading() {
            loadingOverlay.style.display = 'flex';
        }

        function hideLoading() {
            loadingOverlay.style.display = 'none';
        }

        function saveProject() {
            const projectData = {
                transcription: transcriptionText.value,
                enhancedText: enhancedText.value,
                videoSrc: videoPreview.src,
                audioSrc: audioPreview.src
            };
            localStorage.setItem('youtubeRecorderProject', JSON.stringify(projectData));
            alert('Project saved successfully!');
        }

        function loadProject() {
            const savedProject = localStorage.getItem('youtubeRecorderProject');
            if (savedProject) {
                const projectData = JSON.parse(savedProject);
                transcriptionText.value = projectData.transcription;
                enhancedText.value = projectData.enhancedText;
                videoPreview.src = projectData.videoSrc;
                audioPreview.src = projectData.audioSrc;
                wavesurfer.load(projectData.audioSrc);

                downloadVideo.disabled = false;
                downloadAudio.disabled = false;
                enhanceBtn.disabled = false;
                synthesizeBtn.disabled = false;
                alert('Project loaded successfully!');
            } else {
                alert('No saved project found!');
            }
        }

        async function extractAudio() {
            showLoading();
            try {
                const videoFile = await fetch(videoPreview.src).then(r => r.blob());
                const audioContext = new AudioContext();
                const audioBuffer = await audioContext.decodeAudioData(await videoFile.arrayBuffer());
                
                const offlineContext = new OfflineAudioContext(
                    audioBuffer.numberOfChannels,
                    audioBuffer.length,
                    audioBuffer.sampleRate
                );
                
                const source = offlineContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(offlineContext.destination);
                source.start();
                
                const renderedBuffer = await offlineContext.startRendering();
                const audioBlob = new Blob([toWav(renderedBuffer)], { type: 'audio/wav' });
                
                const audioUrl = URL.createObjectURL(audioBlob);
                audioPreview.src = audioUrl;
                wavesurfer.load(audioUrl);
                downloadAudio.disabled = false;
                transcribeBtn.disabled = false;
            } catch (error) {
                console.error('Audio extraction error:', error);
                alert('Error during audio extraction');
            } finally {
                hideLoading();
            }
        }

        function toWav(audioBuffer) {
            const numOfChan = audioBuffer.numberOfChannels;
            const length = audioBuffer.length * numOfChan * 2 + 44;
            const buffer = new ArrayBuffer(length);
            const view = new DataView(buffer);
            const channels = [];
            let sample;
            let offset = 0;
            let pos = 0;

            setUint32(0x46464952);
            setUint32(length - 8);
            setUint32(0x45564157);
            setUint32(0x20746d66);
            setUint32(16);
            setUint16(1);
            setUint16(numOfChan);
            setUint32(audioBuffer.sampleRate);
            setUint32(audioBuffer.sampleRate * 2 * numOfChan);
            setUint16(numOfChan * 2);
            setUint16(16);
            setUint32(0x61746164);
            setUint32(length - pos - 4);

            for (let i = 0; i < audioBuffer.numberOfChannels; i++)
                channels.push(audioBuffer.getChannelData(i));

            while (pos < length) {
                for (let i = 0; i < numOfChan; i++) {
                    sample = Math.max(-1, Math.min(1, channels[i][offset]));
                    sample = (0.5 + sample < 0 ? sample * 32768 : sample * 32767) | 0;
                    view.setInt16(pos, sample, true);
                    pos += 2;
                }
                offset++;
            }

            return buffer;

            function setUint16(data) {
                view.setUint16(pos, data, true);
                pos += 2;
            }

            function setUint32(data) {
                view.setUint32(pos, data, true);
                pos += 4;
            }
        }
    </script>
</body>
</html>