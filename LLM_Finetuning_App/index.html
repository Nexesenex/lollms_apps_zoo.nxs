<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM Finetuning App</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="/web.app.localizer.js"></script>
</head>
<body class="bg-gray-100 min-h-screen">
    <style>
        .help-button {
            background-color: #4A5568;
            color: white;
            border-radius: 50%;
            width: 24px;
            height: 24px;
            font-size: 14px;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            margin-left: 8px;
            cursor: pointer;
            border: none;
        }
        
        .help-button:hover {
            background-color: #2D3748;
        }
        
        .popup-overlay {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 1000;
        }
        
        .popup-content {
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background-color: white;
            padding: 2rem;
            border-radius: 8px;
            max-width: 600px;
            width: 90%;
            max-height: 80vh;
            overflow-y: auto;
            z-index: 1001;
        }
        
        .popup-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 1rem;
        }
        
        .popup-close {
            background: none;
            border: none;
            font-size: 1.5rem;
            cursor: pointer;
            color: #4A5568;
        }
        
        .popup-close:hover {
            color: #2D3748;
        }
        </style>
        
    <div class="container mx-auto px-4 py-8">
        <h1 class="text-3xl font-bold mb-8 text-center text-blue-600" data-translate="title">LLM Finetuning App</h1>
        
        <!-- Tab Navigation -->
        <div class="flex justify-center mb-8">
            <button id="downloadBtn" class="bg-yellow-500 hover:bg-yellow-700 text-white font-bold py-2 px-4 rounded-l focus:outline-none focus:shadow-outline" data-translate="downloadButton">Download Model</button>
            <button id="trainBtn" class="bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 focus:outline-none focus:shadow-outline" data-translate="trainButton">Train</button>
            <button id="fuseBtn" class="bg-green-500 hover:bg-green-700 text-white font-bold py-2 px-4 focus:outline-none focus:shadow-outline" data-translate="fuseButton">Fuse</button>
            <button id="quantizeBtn" class="bg-purple-500 hover:bg-purple-700 text-white font-bold py-2 px-4 rounded-r focus:outline-none focus:shadow-outline" data-translate="quantizeButton">Quantize</button>
        </div>

        <!-- Download Model Form -->
        <div id="downloadForm" class="bg-white shadow-md rounded px-8 pt-6 pb-8 mb-4">
            <h2 class="text-2xl font-bold mb-4" data-translate="downloadTitle">Download Model</h2>
            <form id="downloadModelForm">
                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="downloadModelName" data-translate="downloadModelNameLabel">Model Name (Hugging Face path or local model path)</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="downloadModelName" type="text" placeholder="e.g., bert-base-uncased" required>
                </div>
                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="downloadTargetDir" data-translate="downloadTargetDirLabel">Target Directory</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="downloadTargetDir" type="text" placeholder="e.g., /path/to/save/model" required>
                </div>
                <div class="flex items-center justify-between">
                    <button class="bg-yellow-500 hover:bg-yellow-700 text-white font-bold py-2 px-4 rounded focus:outline-none focus:shadow-outline" type="submit" data-translate="startDownloadButton">Download Model</button>
                </div>
            </form>
        </div>

        <div id="trainForm" class="bg-white shadow-md rounded px-8 pt-6 pb-8 mb-4" style="display: none;">
            <h2 class="text-2xl font-bold mb-4" data-translate="trainTitle" id="trainTitle">Train</h2>
            <form id="finetuneForm">
                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="modelName" data-translate="modelNameLabel">Model Name (Hugging Face path)</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="modelName" type="text" placeholder="e.g., bert-base-uncased" required>
                </div>
                
                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" data-translate="datasetSourceLabel">Dataset Source</label>
                    <div class="mt-2">
                        <label class="inline-flex items-center">
                            <input type="radio" class="form-radio" name="datasetSource" value="huggingface" checked>
                            <span class="ml-2" data-translate="huggingFaceOption">Hugging Face</span>
                        </label>
                        <label class="inline-flex items-center ml-6">
                            <input type="radio" class="form-radio" name="datasetSource" value="local">
                            <span class="ml-2" data-translate="localOption">Local</span>
                        </label>
                    </div>
                </div>
                
                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="datasetName" data-translate="datasetNameLabel">Dataset Name/Path</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="datasetName" type="text" placeholder="Dataset name or local path" required>
                </div>

                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="dataset-format" data-translate="datasetFormatLabel">Dataset Format</label>
                    <select id="dataset-format" name="dataset-format" class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" onchange="toggleCustomFormat()">
                        <option value="single_text" data-translate="singleTextOption">Single Text</option>
                        <option value="instruction_input_output" data-translate="instructionInputOutputOption">Instruction-Input-Output</option>
                        <option value="question_answer" data-translate="questionAnswerOption">Question-Answer</option>
                        <option value="lollms" data-translate="questionAnswerOption">Lollms discussion</option>
                        <option value="custom" data-translate="customOption">Custom</option>
                    </select>
                </div>

                <div id="custom-format-group" class="mb-4" style="display: none;">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="custom-format" data-translate="customFormatLabel">Custom Format</label>
                    <textarea type="text" id="custom-format" name="custom-format" class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" placeholder="e.g. {field1} {field2}: {field3}"></textarea>
                </div>

                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="outputModelPath" data-translate="outputModelPathLabel">Output Model Path</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="outputModelPath" type="text" placeholder="Output Model Path" required>
                </div>

                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="learningRate" data-translate="learningRateLabel">Learning Rate</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="learningRate" type="number" step="0.0001" value="3e-4" required>
                </div>
                
                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="numEpochs" data-translate="numEpochsLabel">Number of Epochs</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="numEpochs" type="number" value="3" required>
                </div>
                
                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="batchSize" data-translate="batchSizeLabel">Batch Size</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="batchSize" type="number" value="4" required>
                </div>
                
                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="gradAccumSteps" data-translate="gradAccumStepsLabel">Gradient Accumulation Steps</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="gradAccumSteps" type="number" value="4" required>
                </div>
                
                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="maxGradNorm" data-translate="maxGradNormLabel">Max Gradient Norm</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="maxGradNorm" type="number" step="0.1" value="0.3" required>
                </div>
                
                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="weightDecay" data-translate="weightDecayLabel">Weight Decay</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="weightDecay" type="number" step="0.001" value="0.001" required>
                </div>
                
                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="loraAlpha" data-translate="loraAlphaLabel">LoRA Alpha</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="loraAlpha" type="number" value="16" required>
                </div>
                
                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="loraDropout" data-translate="loraDropoutLabel">LoRA Dropout</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="loraDropout" type="number" step="0.01" value="0.1" required>
                </div>
                
                <div class="mb-6">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="loraR" data-translate="loraRLabel">LoRA R</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="loraR" type="number" value="8" required>
                </div>
                <div class="mb-6">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="maxSeqLength" data-translate="maxSeqLengthLabel">Max sequence length</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="maxSeqLength" type="number" value="128000" required>
                </div>
                
                <div class="mb-6">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="gpuIds" data-translate="gpuIdsLabel">GPU IDs (comma-separated)</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="gpuIds" type="text" placeholder="e.g., 0,1,2">
                </div>
                
                <div class="mb-6">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="maxMemoryPerGpu" data-translate="maxMemoryPerGpuLabel">Max memory per GPU (e.g., 10GiB)</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="maxMemoryPerGpu" type="text" placeholder="e.g., 10GiB,8GiB">
                </div>
                
                <div class="mb-6">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="maxCpuMemory" data-translate="maxCpuMemoryLabel">Max CPU memory</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="maxCpuMemory" type="text" placeholder="e.g., 30GiB">
                </div>
                
                <div class="mb-6">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="fp16" data-translate="fp16Label">Enable FP16 (Mixed Precision)</label>
                    <input class="mr-2 leading-tight" type="checkbox" id="fp16" checked>
                </div>
                                
                <div class="flex items-center justify-between">
                    <button class="bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded focus:outline-none focus:shadow-outline" type="submit" data-translate="startTrainingButton">Start Training</button>
                </div>
            </form>
        </div>

        <div id="fuseForm" class="bg-white shadow-md rounded px-8 pt-6 pb-8 mb-4" style="display: none;">
            <h2 class="text-2xl font-bold mb-4" data-translate="fuseTitle">Fuse</h2>
            <form id="fusionForm">
                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="baseModelPath" data-translate="baseModelPathLabel">Base Model Path</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="baseModelPath" type="text" required>
                </div>
                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="loraModelPath" data-translate="loraModelPathLabel">LoRA Model Path</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="loraModelPath" type="text" required>
                </div>
                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="fusedOutputPath" data-translate="fusedOutputPathLabel">Fused Output Path</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="fusedOutputPath" type="text" required>
                </div>
                <div class="flex items-center justify-between">
                    <button class="bg-green-500 hover:bg-green-700 text-white font-bold py-2 px-4 rounded focus:outline-none focus:shadow-outline" type="submit" data-translate="startFusionButton">Start Fusion</button>
                </div>
            </form>
        </div>

        <div id="quantizeForm" class="bg-white shadow-md rounded px-8 pt-6 pb-8 mb-4" style="display: none;">
            <h2 class="text-2xl font-bold mb-4" data-translate="quantizeTitle">Quantize</h2>
            <form id="quantizationForm">
                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="modelPathQuantize" data-translate="modelPathQuantizeLabel">Model Path</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="modelPathQuantize" type="text" required>
                </div>
                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="quantizedOutputPath" data-translate="quantizedOutputPathLabel">Quantized Output Path</label>
                    <input class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" id="quantizedOutputPath" type="text" required>
                </div>
                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="quantizationBits" data-translate="quantizationBitsLabel">Quantization Bits</label>
                    <select id="quantizationBits" class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline">
                    <!-- Options will be dynamically populated based on the selected quantization tool -->
                    </select>
                </div>
                <div class="mb-4">
                    <label class="block text-gray-700 text-sm font-bold mb-2" for="quantizationTool" data-translate="quantizationBitsLabel">Quantization Bits</label>
                    <select id="quantizationTool" class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline">
                        <option value="bitsandbytes">bitsandbytes</option>
                        <option value="gguf">GGUF</option>
                    </select>
                </div>
                <div class="flex items-center justify-between">
                    <button class="bg-purple-500 hover:bg-purple-700 text-white font-bold py-2 px-4 rounded focus:outline-none focus:shadow-outline" type="submit" data-translate="startQuantizationButton">Start Quantization</button>
                </div>
            </form>
        </div>
        
        <div id="progressContainer" class="hidden bg-white shadow-md rounded px-8 pt-6 pb-8 mb-4">
            <h2 class="text-xl font-semibold mb-4" data-translate="progressTitle">Progress</h2>
            <div class="w-full bg-gray-200 rounded-full h-2.5 dark:bg-gray-700 mb-4">
                <div id="progressBar" class="bg-blue-600 h-2.5 rounded-full" style="width: 0%"></div>
            </div>
            <pre id="logOutput" class="bg-gray-100 p-4 rounded-lg text-sm h-64 overflow-auto"></pre>
        </div>
    </div>
    <!-- Add this just before the closing body tag -->
    <div id="helpPopup" class="popup-overlay">
        <div class="popup-content">
            <div class="popup-header">
                <h2 id="helpTitle" class="text-xl font-bold"></h2>
                <button class="popup-close" onclick="closeHelpPopup()">×</button>
            </div>
            <div id="helpContent" class="mt-4"></div>
        </div>
    </div>

    <script>
        // Help content dictionary
        const helpContent = {
            // Download section
            "downloadModelName": {
                title: "Model Name (Hugging Face path)",
                content: "Enter the name or path of the model from Hugging Face Hub. For example: 'meta-llama/Llama-2-7b-chat-hf' or 'mistralai/Mistral-7B-v0.1'. Make sure you have the necessary permissions to access the model."
            },
            "downloadTargetDir": {
                title: "Target Directory",
                content: "Specify the local directory where you want to save the downloaded model. Make sure you have sufficient disk space available."
            },

            // Training parameters
            "trainForm": {
                title: "Training Methods Guide",
                content: `Comprehensive guide to different model training techniques with focus on LoRA.
                         
                         LoRA (Low-Rank Adaptation):
                         -----------------------------
                         Purpose:
                         - Efficient fine-tuning of large language models
                         - Reduces memory requirements significantly
                         - Creates small, adaptable modules
                         
                         Best Use Cases for LoRA:
                         - Limited computational resources
                         - Need for multiple specialized adaptations
                         - Quick iterations and experiments
                         - Style transfer or specific domain adaptation
                         - When you want to combine multiple fine-tunes
                         
                         Advantages:
                         - Very memory efficient (typically 2-4GB GPU RAM)
                         - Small checkpoint sizes (typically <100MB)
                         - Can be merged with other LoRA adaptations
                         - Faster training times
                         - Original model remains unchanged
                         
                         Limitations:
                         - May not capture very complex adaptations
                         - Limited by base model capabilities
                         - Not suitable for fundamental architecture changes
                         
                         Alternative Training Methods:
                         -----------------------------
                         1. Full Fine-tuning:
                            When to use:
                            - Have substantial computational resources
                            - Need deep architectural changes
                            - Want maximum adaptation capability
                            - Have large, high-quality datasets
                            
                            Drawbacks:
                            - Requires lots of GPU memory (16GB+)
                            - Long training times
                            - Large checkpoint sizes
                            - Risk of catastrophic forgetting
                         
                         2. QLoRA (Quantized LoRA):
                            When to use:
                            - Even more limited resources than LoRA
                            - Want to fine-tune larger models
                            - Need similar results to full fine-tuning
                            
                            Advantages:
                            - Even lower memory requirements
                            - Comparable results to full fine-tuning
                            
                            Drawbacks:
                            - Slightly slower training
                            - Requires specific quantization-aware training
                         
                         3. Prefix/Prompt Tuning:
                            When to use:
                            - Need extremely lightweight adaptations
                            - Focus on specific tasks
                            - Want fastest possible training
                            
                            Limitations:
                            - More limited in adaptation scope
                            - May not capture complex patterns
                         
                         Best Practices for LoRA Training:
                         --------------------------------
                         1. Dataset Preparation:
                            - Clean, high-quality data
                            - Consistent formatting
                            - Appropriate size (typically 100-10000 samples)
                            
                         2. Hyperparameter Selection:
                            - Start with standard values (alpha=16, r=8)
                            - Adjust based on results
                            - Monitor training loss
                            
                         3. Training Duration:
                            - Start with small epochs (3-5)
                            - Use early stopping
                            - Monitor for overfitting
                         
                         4. Model Selection:
                            - Choose appropriate base model
                            - Consider model size vs task complexity
                            - Verify token limit requirements
                         
                         Common Pitfalls:
                         ----------------
                         - Overfitting on small datasets
                         - Using too high alpha/r for simple tasks
                         - Insufficient training data quality
                         - Not validating results properly
                         - Incorrect learning rate selection
                         
                         Optimization Tips:
                         -----------------
                         - Use gradient checkpointing for larger models
                         - Implement proper validation
                         - Start conservative with hyperparameters
                         - Test on diverse inputs
                         - Keep training data well-structured
                         
                         When to Switch Methods:
                         ----------------------
                         Consider full fine-tuning if:
                         - LoRA results are insufficient
                         - Need fundamental behavior changes
                         - Have adequate computational resources
                         
                         Consider QLoRA if:
                         - Need more adaptation power than LoRA
                         - Have very limited resources
                         - Working with larger base models
                         
                         Consider Prefix Tuning if:
                         - Need extremely fast adaptation
                         - Have very specific, narrow tasks
                         - Want smallest possible footprint`
            },
        
            "learningRate": {
                title: "Learning Rate",
                content: `The learning rate controls how much the model parameters are updated during training.
                        - Too high: Training may be unstable or fail to converge
                        - Too low: Training may be too slow
                        - Recommended range: 1e-5 to 5e-4
                        - Default: 3e-4 (0.0003)
                        
                        Examples:
                        - 1e-4: Conservative learning rate, stable but slower training
                        - 5e-4: Faster training but might be less stable
                        - 2e-5: Very conservative, use for fine-tuning delicate tasks`
            },
            "numEpochs": {
                title: "Number of Epochs",
                content: `The number of times the model will iterate through the entire dataset.
                        - Too few: Model might underfit
                        - Too many: Model might overfit
                        - Recommended range: 1-10
                        
                        Examples:
                        - 1-2 epochs: Quick adaptation for similar tasks
                        - 3-5 epochs: Standard fine-tuning
                        - 5+ epochs: Deep specialization (watch for overfitting)`
            },
            "batchSize": {
                title: "Batch Size",
                content: `Number of training examples processed in one forward/backward pass.
                        - Larger: Better training stability, more VRAM required
                        - Smaller: Less VRAM required, potentially noisier training
                        
                        Examples:
                        - 1: Minimum size, highest noise in gradients
                        - 4: Good balance for most GPUs
                        - 8+: For high-end GPUs, more stable training`
            },
            "loraAlpha": {
                title: "LoRA Alpha",
                content: `Scaling factor for LoRA adaptations.
                        - Higher values: Stronger adaptation effect
                        - Lower values: More conservative changes
                        
                        Examples:
                        - 16: Standard value, good for most cases
                        - 32: Stronger adaptation
                        - 8: More conservative adaptation`
            },
            "loraR": {
                title: "LoRA R",
                content: `Rank of LoRA adaptations. Controls the capacity of the adaptation.
                        - Higher values: More capacity but larger model
                        - Lower values: More efficient but limited capacity
                        
                        Examples:
                        - 8: Standard value, good balance
                        - 16: Higher capacity, larger file size
                        - 4: More efficient, limited capacity`
            },
            "weightDecay": {
                title: "Weight Decay",
                content: `Weight decay is a regularization technique that prevents model overfitting by adding a penalty for large weights.
                        
                        Technical Details:
                        - Adds L2 regularization to the model's parameters
                        - Helps prevent extreme parameter values
                        - Makes the model more generalizable
                        
                        Recommended values:
                        - 0.01: Strong regularization
                        - 0.001: Standard value for most cases
                        - 0.0001: Light regularization
                        
                        Effects:
                        - Higher values: More aggressive regularization, simpler model
                        - Lower values: Less regularization, model can be more expressive
                        - Zero: No weight decay, maximum model flexibility (risk of overfitting)
                        
                        Use cases:
                        - Small datasets: Use higher values (0.01-0.001)
                        - Large datasets: Can use lower values (0.001-0.0001)
                        - When overfitting: Increase the value
                        - When underfitting: Decrease the value`
            },

            "loraDropout": {
                title: "LoRA Dropout",
                content: `LoRA dropout is a regularization parameter specific to LoRA adapters that helps prevent overfitting.
                        
                        Technical Details:
                        - Randomly drops connections in LoRA layers during training
                        - Helps create more robust adaptations
                        - Similar to standard dropout but specific to LoRA matrices
                        
                        Recommended values:
                        - 0.1 (10%): Standard value, good for most cases
                        - 0.2 (20%): Stronger regularization
                        - 0.05 (5%): Lighter regularization
                        
                        Effects:
                        - Higher values: More regularization, slower convergence
                        - Lower values: Less regularization, faster convergence
                        - Zero: No dropout (not recommended)
                        
                        When to adjust:
                        - Increase if: Model is overfitting or memorizing
                        - Decrease if: Model is struggling to learn
                        - For very small datasets: Consider higher values (0.15-0.2)
                        - For very large datasets: Can use lower values (0.05-0.1)`
            },

            "maxSeqLength": {
                title: "Maximum Sequence Length",
                content: `Defines the maximum number of tokens that can be processed in a single forward pass.
                        
                        Technical Details:
                        - Affects both training and inference
                        - Longer sequences require more memory
                        - Must be <= model's architecture limit
                        
                        Common values:
                        - 512: Standard for BERT-like models
                        - 1024: Common for medium-length tasks
                        - 2048: Standard for many LLMs
                        - 4096-32000: Extended context models
                        
                        Effects:
                        - Larger values:
                        • Can process longer texts
                        • Requires more GPU memory
                        • Slower training and inference
                        
                        - Smaller values:
                        • More memory efficient
                        • Faster training
                        • May truncate important context
                        
                        Considerations:
                        - Check your GPU memory capacity
                        - Consider your task's typical input length
                        - Balance between context length and training efficiency`
            },

            "fp16": {
                title: "Enable FP16 (Mixed Precision)",
                content: `Mixed precision training using 16-bit floating-point numbers alongside 32-bit floating-point.
                        
                        Technical Benefits:
                        - Reduces memory usage (up to 50%)
                        - Faster training (typically 2-3x)
                        - Lower memory bandwidth usage
                        
                        When to use:
                        - YES if:
                        • Using modern NVIDIA GPU (Volta, Turing, Ampere, or newer)
                        • Need to fit larger batches in memory
                        • Want faster training
                        
                        - NO if:
                        • Using older GPUs
                        • Experiencing training instability
                        • Working with very small or sensitive numbers
                        
                        Important Notes:
                        - Maintains FP32 master weights for stability
                        - Automatic loss scaling prevents underflow
                        - May require slight hyperparameter adjustments
                        - Some operations remain in FP32 for stability
                        
                        Debugging Tips:
                        - If training becomes unstable, check for NaN values
                        - Consider reducing learning rate slightly
                        - Monitor loss scaling statistics`
            }
        };

        // Function to add help buttons to all form fields
        function addHelpButtons() {
            document.querySelectorAll('label[for]').forEach(label => {
                const forAttribute = label.getAttribute('for');
                if (helpContent[forAttribute]) {
                    const helpButton = document.createElement('button');
                    helpButton.className = 'help-button';
                    helpButton.innerHTML = '?';
                    helpButton.onclick = (e) => {
                        e.preventDefault();
                        showHelpPopup(forAttribute);
                    };
                    label.appendChild(helpButton);
                }
            });
            const train_title = document.getElementById("trainTitle")
            const helpButton = document.createElement('button');
            helpButton.className = 'help-button';
            helpButton.innerHTML = '?';
            helpButton.onclick = (e) => {
                e.preventDefault();
                showHelpPopup("trainForm");
            };
            train_title.appendChild(helpButton);

        }

        // Function to show help popup
        function showHelpPopup(fieldId) {
            const helpData = helpContent[fieldId];
            if (helpData) {
                document.getElementById('helpTitle').textContent = helpData.title;
                document.getElementById('helpContent').innerHTML = helpData.content.replace(/\n/g, '<br>');
                document.getElementById('helpPopup').style.display = 'block';
            }
        }

        // Function to close help popup
        function closeHelpPopup() {
            document.getElementById('helpPopup').style.display = 'none';
        }

        // Close popup when clicking outside
        document.getElementById('helpPopup').addEventListener('click', function(e) {
            if (e.target === this) {
                closeHelpPopup();
            }
        });

        // Initialize help buttons when the document is loaded
        document.addEventListener('DOMContentLoaded', function() {
            addHelpButtons();
            const forms = ['downloadModelForm', 'finetuneForm', 'fusionForm', 'quantizationForm'];
            
            // Load saved states
            forms.forEach(formId => loadFormState(formId));
            
            // Save states on input change
            forms.forEach(formId => {
                const form = document.getElementById(formId);
                if (form) {
                    ['input', 'change'].forEach(eventType => {
                        form.addEventListener(eventType, () => saveFormState(formId));
                    });
                }
            });            
        });


        // Define the available options for each quantization tool
        const quantizationOptions = {
            bitsandbytes: [
                { value: 'q8_0', text: 'q8_0' },
                { value: 'q4_0', text: 'q4_0' }
            ],
            gguf: [
                { value: 'fast_quantized', text: 'fast_quantized' },
                { value: 'quantized', text: 'quantized' },
                { value: 'f32', text: 'f32' },
                { value: 'f16', text: 'f16' },
                { value: 'q8_0', text: 'q8_0' },
                { value: 'q4_k_m', text: 'q4_k_m' },
                { value: 'q5_k_m', text: 'q5_k_m' },
                { value: 'q2_k', text: 'q2_k' },
                { value: 'q3_k_l', text: 'q3_k_l' },
                { value: 'q3_k_m', text: 'q3_k_m' },
                { value: 'q3_k_s', text: 'q3_k_s' },
                { value: 'q4_0', text: 'q4_0' },
                { value: 'q4_1', text: 'q4_1' },
                { value: 'q4_k_s', text: 'q4_k_s' },
                { value: 'q4_k', text: 'q4_k' },
                { value: 'q5_k', text: 'q5_k' },
                { value: 'q5_0', text: 'q5_0' },
                { value: 'q5_1', text: 'q5_1' },
                { value: 'q5_k_s', text: 'q5_k_s' },
                { value: 'q6_k', text: 'q6_k' },
                { value: 'iq2_xxs', text: 'iq2_xxs' },
                { value: 'iq2_xs', text: 'iq2_xs' },
                { value: 'iq3_xxs', text: 'iq3_xxs' },
                { value: 'q3_k_xs', text: 'q3_k_xs' }
            ]
        };

        // Function to populate the quantization bits dropdown based on the selected tool
        function updateQuantizationBits() {
            const quantizationTool = document.getElementById('quantizationTool').value;
            const quantizationBits = document.getElementById('quantizationBits');

            // Clear existing options
            quantizationBits.innerHTML = '';

            // Get the relevant options for the selected tool
            const options = quantizationOptions[quantizationTool];

            // Populate the dropdown with the new options
            options.forEach(option => {
                const opt = document.createElement('option');
                opt.value = option.value;
                opt.textContent = option.text;
                quantizationBits.appendChild(opt);
            });
        }

        // Add event listener to the quantization tool dropdown
        document.getElementById('quantizationTool').addEventListener('change', updateQuantizationBits);

        // Initialize the quantization bits dropdown on page load
        updateQuantizationBits();


        const downloadForm = document.getElementById('downloadForm');
        const trainForm = document.getElementById('trainForm');
        const fuseForm = document.getElementById('fuseForm');
        const quantizeForm = document.getElementById('quantizeForm');
        const progressContainer = document.getElementById('progressContainer');
        const progressBar = document.getElementById('progressBar');
        const logOutput = document.getElementById('logOutput');

        const trainBtn = document.getElementById('trainBtn');
        const fuseBtn = document.getElementById('fuseBtn');
        const quantizeBtn = document.getElementById('quantizeBtn');

        let socket;

        function toggleCustomFormat() {
            var formatSelect = document.getElementById('dataset-format');
            var customFormatGroup = document.getElementById('custom-format-group');
            
            if (formatSelect.value === 'custom') {
                customFormatGroup.style.display = 'block';
            } else {
                customFormatGroup.style.display = 'none';
            }
        }

        downloadForm.addEventListener('click', () => {
            downloadForm.style.display = 'block';
            trainForm.style.display = 'none';
            fuseForm.style.display = 'none';
            quantizeForm.style.display = 'none';
        });

        trainBtn.addEventListener('click', () => {
            downloadForm.style.display = 'none';
            trainForm.style.display = 'block';
            fuseForm.style.display = 'none';
            quantizeForm.style.display = 'none';
        });

        fuseBtn.addEventListener('click', () => {
            downloadForm.style.display = 'none';
            trainForm.style.display = 'none';
            fuseForm.style.display = 'block';
            quantizeForm.style.display = 'none';
        });

        quantizeBtn.addEventListener('click', () => {
            downloadForm.style.display = 'none';
            trainForm.style.display = 'none';
            fuseForm.style.display = 'none';
            quantizeForm.style.display = 'block';
        });

        document.getElementById('downloadBtn').addEventListener('click', function() {
            document.getElementById('downloadForm').style.display = 'block';
            document.getElementById('trainForm').style.display = 'none';
            document.getElementById('fuseForm').style.display = 'none';
            document.getElementById('quantizeForm').style.display = 'none';
        });

        // Form submission logic for downloading the model
        document.getElementById('downloadModelForm').addEventListener('submit', async function(event) {
            event.preventDefault();

            const modelName = document.getElementById('downloadModelName').value;
            const targetDir = document.getElementById('downloadTargetDir').value;

            try {
                const response = await fetch('/download_model/', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        model_name: modelName,
                        target_dir: targetDir,
                    }),
                });

                const result = await response.json();

                if (response.ok) {
                    alert(result.message);
                } else {
                    alert(`Error: ${result.detail}`);
                }
            } catch (error) {
                console.error('Error downloading model:', error);
                alert('An error occurred while downloading the model.');
            }
        });

        document.getElementById('finetuneForm').addEventListener('submit', async (e) => {
            e.preventDefault();
            
            const jsonData = {
                model_name: document.getElementById('modelName').value,
                dataset_source: document.querySelector('input[name="datasetSource"]:checked').value,
                dataset_name: document.getElementById('datasetName').value,
                dataset_format: document.getElementById('dataset-format').value,
                custom_format: document.getElementById('custom-format').value,
                output_model_path: document.getElementById('outputModelPath').value,
                learning_rate: parseFloat(document.getElementById('learningRate').value),
                num_train_epochs: parseInt(document.getElementById('numEpochs').value),
                per_device_train_batch_size: parseInt(document.getElementById('batchSize').value),
                gradient_accumulation_steps: parseInt(document.getElementById('gradAccumSteps').value),
                max_grad_norm: parseFloat(document.getElementById('maxGradNorm').value),
                weight_decay: parseFloat(document.getElementById('weightDecay').value),
                lora_alpha: parseInt(document.getElementById('loraAlpha').value),
                lora_dropout: parseFloat(document.getElementById('loraDropout').value),
                lora_r: parseInt(document.getElementById('loraR').value),
                max_seq_length: parseInt(document.getElementById('maxSeqLength').value),
                gpu_ids: document.getElementById('gpuIds').value.trim() !== '' ? document.getElementById('gpuIds').value.split(',').map(id => parseInt(id.trim())).filter(id => !isNaN(id)): undefined,
                max_memory_per_gpu: document.getElementById('maxMemoryPerGpu').value.trim() !== '' 
                ? document.getElementById('maxMemoryPerGpu').value.split(',').reduce((obj, val, index) => {
                    const trimmedVal = val.trim();
                    if (trimmedVal !== '') {
                        obj[index] = trimmedVal;
                    }
                    return obj;
                }, {})
                : undefined,
                max_cpu_memory: document.getElementById('maxCpuMemory').value.trim() !== '' 
                ? document.getElementById('maxCpuMemory').value.trim()
                : undefined,
                fp16: document.getElementById('fp16').checked

            };

            try {
                const response = await fetch('/train', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify(jsonData),
                });
                
                if (response.ok) {
                    progressContainer.classList.remove('hidden');
                    trainForm.style.display = 'none';
                    initWebSocket();
                } else {
                    throw new Error('Training initialization failed');
                }
            } catch (error) {
                console.error('Error:', error);
                alert('An error occurred while starting the training process.');
            }
        });

        document.getElementById('fusionForm').addEventListener('submit', async (e) => {
            e.preventDefault();
            
            const jsonData = {
                base_model_path: document.getElementById('baseModelPath').value,
                lora_model_path: document.getElementById('loraModelPath').value,
                output_path: document.getElementById('fusedOutputPath').value
            };

            try {
                const response = await fetch('/fuse', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify(jsonData),
                });
                
                if (response.ok) {
                    progressContainer.classList.remove('hidden');
                    fuseForm.style.display = 'none';
                    initWebSocket();
                } else {
                    throw new Error('Fusion initialization failed');
                }
            } catch (error) {
                console.error('Error:', error);
                alert('An error occurred while starting the fusion process.');
            }
        });

        document.getElementById('quantizationForm').addEventListener('submit', async (e) => {
            e.preventDefault();
            
            const jsonData = {
                model_path: document.getElementById('modelPathQuantize').value,
                output_path: document.getElementById('quantizedOutputPath').value,
                quantization_bits: document.getElementById('quantizationBits').value,
                quantization_tool: document.getElementById('quantizationTool').value
            };

            try {
                const response = await fetch('/quantize', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify(jsonData),
                });
                
                if (response.ok) {
                    progressContainer.classList.remove('hidden');
                    quantizeForm.style.display = 'none';
                    initWebSocket();
                } else {
                    throw new Error('Quantization initialization failed');
                }
            } catch (error) {
                console.error('Error:', error);
                alert('An error occurred while starting the quantization process.');
            }
        });

        function initWebSocket() {
            socket = new WebSocket('ws://localhost:8000/ws');
            
            socket.onmessage = (event) => {
                const data = JSON.parse(event.data);
                updateProgress(data);
            };
            socket.onclose = () => {
                console.log('WebSocket connection closed');
            };
        }

        function updateProgress(data) {
            if (data.progress !== undefined) {
                progressBar.style.width = `${data.progress}%`;
            }
            if (data.log) {
                logOutput.textContent += data.log + '\n';
                logOutput.scrollTop = logOutput.scrollHeight;
            }
        }

        const translations = {
            en: {
                name: "English",
                translations: {
                    "title": "LLM Finetuning App",
                    "trainButton": "Train",
                    "fuseButton": "Fuse",
                    "quantizeButton": "Quantize",
                    "trainTitle": "Train",
                    "fuseTitle": "Fuse",
                    "quantizeTitle": "Quantize",
                    "modelNameLabel": "Model Name (Hugging Face path)",
                    "datasetSourceLabel": "Dataset Source",
                    "huggingFaceOption": "Hugging Face",
                    "localOption": "Local",
                    "datasetNameLabel": "Dataset Name/Path",
                    "datasetFormatLabel": "Dataset Format",
                    "singleTextOption": "Single Text",
                    "instructionInputOutputOption": "Instruction-Input-Output",
                    "questionAnswerOption": "Question-Answer",
                    "customOption": "Custom",
                    "customFormatLabel": "Custom Format",
                    "outputModelPathLabel": "Output Model Path",
                    "learningRateLabel": "Learning Rate",
                    "numEpochsLabel": "Number of Epochs",
                    "batchSizeLabel": "Batch Size",
                    "gradAccumStepsLabel": "Gradient Accumulation Steps",
                    "maxGradNormLabel": "Max Gradient Norm",
                    "weightDecayLabel": "Weight Decay",
                    "loraAlphaLabel": "LoRA Alpha",
                    "loraDropoutLabel": "LoRA Dropout",
                    "loraRLabel": "LoRA R",
                    "startTrainingButton": "Start Training",
                    "baseModelPathLabel": "Base Model Path",
                    "loraModelPathLabel": "LoRA Model Path",
                    "fusedOutputPathLabel": "Fused Output Path",
                    "startFusionButton": "Start Fusion",
                    "modelPathQuantizeLabel": "Model Path",
                    "quantizedOutputPathLabel": "Quantized Output Path",
                    "quantizationBitsLabel": "Quantization Bits",
                    "startQuantizationButton": "Start Quantization",
                    "progressTitle": "Progress"
                }
            },
            fr: {
                name: "Français",
                translations: {
                    "title": "Application de Fine-tuning LLM",
                    "trainButton": "Entraîner",
                    "fuseButton": "Fusionner",
                    "quantizeButton": "Quantifier",
                    "trainTitle": "Entraînement",
                    "fuseTitle": "Fusion",
                    "quantizeTitle": "Quantification",
                    "modelNameLabel": "Nom du modèle (chemin Hugging Face)",
                    "datasetSourceLabel": "Source du jeu de données",
                    "huggingFaceOption": "Hugging Face",
                    "localOption": "Local",
                    "datasetNameLabel": "Nom/Chemin du jeu de données",
                    "datasetFormatLabel": "Format du jeu de données",
                    "singleTextOption": "Texte simple",
                    "instructionInputOutputOption": "Instruction-Entrée-Sortie",
                    "questionAnswerOption": "Question-Réponse",
                    "customOption": "Personnalisé",
                    "customFormatLabel": "Format personnalisé",
                    "outputModelPathLabel": "Chemin du modèle de sortie",
                    "learningRateLabel": "Taux d'apprentissage",
                    "numEpochsLabel": "Nombre d'époques",
                    "batchSizeLabel": "Taille du lot",
                    "gradAccumStepsLabel": "Étapes d'accumulation du gradient",
                    "maxGradNormLabel": "Norme de gradient maximale",
                    "weightDecayLabel": "Décroissance des poids",
                    "loraAlphaLabel": "LoRA Alpha",
                    "loraDropoutLabel": "LoRA Dropout",
                    "loraRLabel": "LoRA R",
                    "startTrainingButton": "Commencer l'entraînement",
                    "baseModelPathLabel": "Chemin du modèle de base",
                    "loraModelPathLabel": "Chemin du modèle LoRA",
                    "fusedOutputPathLabel": "Chemin de sortie fusionné",
                    "startFusionButton": "Commencer la fusion",
                    "modelPathQuantizeLabel": "Chemin du modèle",
                    "quantizedOutputPathLabel": "Chemin de sortie quantifié",
                    "quantizationBitsLabel": "Bits de quantification",
                    "startQuantizationButton": "Commencer la quantification",
                    "progressTitle": "Progression"
                }
            }
        };

        const languageSelector = document.createElement('select');
        languageSelector.id = 'languageSelector';
        languageSelector.className = 'absolute top-4 right-4 bg-white border border-gray-300 text-gray-700 py-2 px-4 rounded leading-tight focus:outline-none focus:bg-white focus:border-gray-500';
        document.body.appendChild(languageSelector);

        const localizer = new WebAppLocalizer(translations, 'llm_finetuning_app_', languageSelector);
        localizer.apply();




        // Save form values to localStorage
        function saveFormState(formId) {
            const form = document.getElementById(formId);
            if (!form) return;

            const formData = {};
            form.querySelectorAll('input, select, textarea').forEach(element => {
                const value = element.type === 'checkbox' ? element.checked : element.value;
                formData[element.id] = value;
            });
            localStorage.setItem(formId, JSON.stringify(formData));
        }

        // Load form values from localStorage
        function loadFormState(formId) {
            const form = document.getElementById(formId);
            if (!form) return;

            const savedData = localStorage.getItem(formId);
            if (savedData) {
                const formData = JSON.parse(savedData);
                Object.entries(formData).forEach(([id, value]) => {
                    const element = document.getElementById(id);
                    if (element) {
                        if (element.type === 'checkbox') {
                            element.checked = value;
                        } else {
                            element.value = value;
                        }
                    }
                });
            }
        }


    </script>
</body>
</html>
